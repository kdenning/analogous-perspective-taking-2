---
title: "Analogous Experiment 2 - Results"
output: 
    html_document:
      code_download: TRUE
      toc: TRUE
      toc_float:
        collapsed: FALSE
      toc_depth: 1
      code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r data prep, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
# Loading packages
library(psych)
library(lme4)
library(sjPlot)
library(effects)
library(magrittr) # part of the tidyverse but must be read in on its own
library(parameters)
library(dplyr)
library(tidyr)
library(rio)

# Functions to clean document, get data from wide to long format
source("functions/Cleaning.R")
source("functions/repeat_funcs.R")

# Setting global chunk options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)

options(scipen = 999)

# Importing data
wide_raw <- import("data/analog2_wide_pt to remove.csv") 

# Cleaning data using functions
wide_data_clean <- wide_factor_clean(wide_raw)

long_data <- wide_to_long(wide_data_clean)
```

# Descriptives {.tabset .tabset-fade .tabset-pills}

## Overall descriptives

```{r}
psych::describe(long_data)
```

## Histograms

### Confirmatory

```{r confirmatory}
hist(long_data$ingroup_ident)

hist(long_data$threat)
````

Identification is roughly normal, while threat is closer to flat.

## Correlations

## Boxplots

```{r confirmatory}
box_ident_res <- boxplot(long_data$ingroup_ident)

boxplot(long_data$threat)

range(box_ident_res$out)

sd <- round(sd(na.omit(long_data$ingroup_ident)),2)
mean <- round(mean(na.omit(long_data$ingroup_ident)),2)
upper_cut <- mean + 3*sd
lower_cut <- mean - 3*sd

long_data %>% 
  select(sub_id, ingroup_ident) %>% 
  unique() %>% 
  filter(ingroup_ident < lower_cut | ingroup_ident > upper_cut)
```

The outliers are not over our criteria of 3 SD so they will not be removed. Plus, they are theoretically important as the weakly identified individuals.

```{r exporatory}
boxplot(long_data$target_bfi_value ~ long_data$covid1) 

boxplot(long_data$target_bfi_value ~ long_data$covid2)

boxplot(long_data$target_bfi_value ~ long_data$covid3)
```

# Demographics {.tabset .tabset-fade .tabset-pills}

## Sample Size

### Overall:

```{r n}
long_data %>% 
  select(sub_id) %>% 
  unique() %>% 
  nrow()
```

### N per Voting Opinion

```{r n by group and voting opin}
long_data %>% 
  select(sub_id, cand_pref) %>% 
  unique() %>% 
  group_by(cand_pref) %>% 
  count()
```

I'm wondering with so few Trump supporters if we should remove them from the analysis... There isn't enough for a comparison condition

## Gender

```{r gender}
long_data %>% 
  na.omit() %>% 
  select(sub_id, gender) %>% 
  unique() %>% 
  group_by(gender) %>% 
  count()
```

## Race/Ethnicity

```{r race}
ethnicity_counts <- long_data %>% 
  select(sub_id, ethnicity) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(ethnicity) %>% 
  count()

ethnicity_counts %>% 
  mutate(n_total = sum(ethnicity_counts$n),
    percent = n/n_total*100) %>% 
  select(-n_total)
```

## Age

```{r age}
long_data %>% 
  select(sub_id, age) %>% 
  na.omit() %>% 
  summarize(mean = mean(age),
            sd = sd(age))
```

## COVID Questions

### Personal experience with COVID

```{r}
long_data %>% 
  select(sub_id, covid1) %>% 
  unique() %>% 
  group_by(covid1) %>% 
  count()
```

### How many people they see

```{r}
long_data %>% 
  select(sub_id, covid2) %>% 
  unique() %>% 
  group_by(covid2) %>% 
  count()
```

### Most important issue related to COVID

```{r}
long_data %>% 
  select(sub_id, covid3) %>% 
  unique() %>% 
  group_by(covid3) %>% 
  count()
```

# Results - Basic Model

```{r}
# Listwise removal of missing data per item
model_data <- long_data %>% 
  select(sub_id, bfi_number, cand_pref, ingroup_ident, threat, 
         self, target_number_collapsed, target_bfi_value, 
         condition_order, covid1, covid2, covid3, target_group,
         ingroup_ident_c, self_c) %>% 
  na.omit(long_data)

```

## Contrasts

### Target number

```{r contrasts 1}
## Dummy coding with first target as reference as wanted
contrasts(model_data$target_number_collapsed) 
```

### Target group

```{r contrasts 2}
## Levels for target group were opposite, so switched them and applied effects coding
## for between-subjects differences of target (which is based on political preference
## - it is the opposite of the target's preference)
levels(model_data$target_group)
model_data$target_group <- relevel(model_data$target_group, "Trump Supporter Target")
contrasts(model_data$target_group) <- contr.sum(2)
```

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_base <- lmer(target_bfi_value ~ self_c*target_number_collapsed + (1 | sub_id), data = model_data)
```

## Residuals

```{r}
model_data$predict <- predict(model_base)

model_data$resid <- model_data$target_bfi_value - model_data$predict

model_data$zresid <- (model_data$resid - mean(model_data$resid))/sd(model_data$resid)
```

### Normality of Level 1 Residuals

```{r}
hist(model_data$zresid)
```

*Did not do residuals for level 2 as we ended up not doing RE for predictors due to convergence issues.*

### Heteroscadasticity: Responses for Self

```{r}
resid_mod1 <- lm(model_data$zresid ~ model_data$self_c)

par(mfrow=c(2,2))
plot(resid_mod1)
par(mfrow=c(1,1))
```

### Heteroscadasticity: Responses for target number

```{r}
resid_mod2 <- lm(model_data$zresid ~ model_data$target_number_collapsed)

plot(x = model_data$target_number_collapsed, 
     y = model_data$zresid, 
     main = "Heteroscedasticity",
     xlab = "Target number/order",
     ylab = "Residuals",
     cex = 0.5, 
     pch = 19)

abline(resid_mod2, col = "darkred")
```

## Results
```{r}
tab_model(model_base,
          digits = 3)
```

## Plot

```{r}
mod1_effects <- get_me_effects(model_base, 
                               "self_c:target_number_collapsed", 
                               target_number_collapsed,
                               "target_1",
                               "target_2")

ggplot(mod1_effects, aes(self_c, fit, group = target_number_collapsed)) +
    geom_smooth(method = "lm", 
                se = FALSE, 
                size = .7, 
                colour = "black", 
                aes(linetype = target_number_collapsed)) +
    theme_minimal(base_size = 13) +
    theme(legend.key.size = unit(1, "cm"))

```

We see that people counter-project at the beginning but not with the second target (after the intervention). What this study is missing is a comparison to another intervention - what my dissertation should have, but should still remain pre-post.

# Model 2 - Interaction w/ Identification

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_ident <- lmer(target_bfi_value ~ self_c*target_number_collapsed*ingroup_ident + (1 | sub_id), data = model_data)
```

Check residuals and heterogeneity of ingroup identification!!!!!!!!!!!!!!!

## Results

```{r}
tab_model(model_ident,
          digits = 3)
```

We see a significant effect of in-group identification that makes the effect of the intervention only trending. We do not see an interaction.

## Model 3 - Interaction w/ threat

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_threat <- lmer(target_bfi_value ~ self_c*target_number_collapsed*threat + (1 | sub_id), data = model_data)
```

Check residuals and heterogeneity of ingroup identification!!!!!!!!!!!!!!!

## Results

```{r}
tab_model(model_threat,
          digits = 3)
```

Unlike in-group identification, threat does not remove the effect of the interaction, even though it also has a significant main effect. Still, there is not interaction of the interaction with threat.

## Exp. Model - Voting preference

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_vote <- lmer(target_bfi_value ~ self_c*target_number_collapsed*target_group + (1 | sub_id), data = model_data)
```

Check residuals and heterogeneity of ingroup identification!!!!!!!!!!!!!!!

## Results

```{r}
tab_model(model_vote,
          digits = 3)
```

This has interactions and main effects on every effect. However, with how small the participant pool is in terms of who voted for Trump, I'm not sure this is reliable but probably is spurious. We could try to get money to get an equal sample of both sides - WOULD NEED PROLIFIC AND MONEY.

## Exp. Model - COVID 1

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_covid1 <- lmer(target_bfi_value ~ self_c*target_number_collapsed*covid1 + (1 | sub_id), data = model_data)
```

Check residuals and heterogeneity of ingroup identification!!!!!!!!!!!!!!!

## Results

```{r}
tab_model(model_covid1,
          digits = 3)
```

Nothing new significant

## Exp. Model - COVID 2

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_covid2 <- lmer(target_bfi_value ~ self_c*target_number_collapsed*covid2 + (1 | sub_id), data = model_data)
```

Check residuals and heterogeneity of ingroup identification!!!!!!!!!!!!!!!

## Results

```{r}
tab_model(model_covid2,
          digits = 3)
```

Interaction

## Exp. Model - COVID 3

```{r}
# model with target number nested within sub_id did not converge because not enough to be RE
# Model with self items as RE also did not converge
model_covid3 <- lmer(target_bfi_value ~ self_c*target_number_collapsed*covid3 + (1 | sub_id), data = model_data)
```

Check residuals and heterogeneity of ingroup identification!!!!!!!!!!!!!!!

## Results

```{r}
tab_model(model_covid3,
          digits = 3)
```

Main effects no interactions.
