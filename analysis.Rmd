---
title: "Analogous Experiment 2 - Results"
output: 
    html_document:
      code_download: TRUE
      toc: TRUE
      toc_float:
        collapsed: FALSE
      toc_depth: 1
      code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r data prep, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
# Loading packages
library(psych)
library(lme4)
library(nlme)
library(sjPlot)
library(effects)
library(magrittr) # part of the tidyverse but must be read in on its own
library(parameters)
library(dplyr)
library(tidyr)
library(rio)
library(ggplot2)

# Functions to clean document, get data from wide to long format
source("functions/Cleaning.R")

# Setting global chunk options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)

options(scipen = 999)

# Importing data
wide_raw <- import("data/analog2_wide_pt to remove.csv") 

# Cleaning data using functions
wide_data_clean <- wide_factor_clean(wide_raw)

long_data <- wide_to_long(wide_data_clean)
```

# Descriptives {.tabset .tabset-fade .tabset-pills}

## Overall descriptives

```{r}
psych::describe(long_data)
```

## Histograms

### Confirmatory

```{r}
hist(long_data$ingroup_ident)

hist(long_data$threat)
````

Identification is roughly normal, while threat is closer to flat.

## Correlations

## Boxplots

```{r}
box_ident_res <- boxplot(long_data$ingroup_ident)

boxplot(long_data$threat)

range(box_ident_res$out)

sd <- round(sd(na.omit(long_data$ingroup_ident)),2)
mean <- round(mean(na.omit(long_data$ingroup_ident)),2)
upper_cut <- mean + 3*sd
lower_cut <- mean - 3*sd

long_data %>% 
  select(sub_id, ingroup_ident) %>% 
  unique() %>% 
  filter(ingroup_ident < lower_cut | ingroup_ident > upper_cut)
```

The outliers are not over our criteria of 3 SD so they will not be removed. Plus, they are theoretically important as the weakly identified individuals.

```{r}
boxplot(long_data$target_bfi_value ~ long_data$covid1) 

boxplot(long_data$target_bfi_value ~ long_data$covid2)

boxplot(long_data$target_bfi_value ~ long_data$covid3)
```

# Demographics {.tabset .tabset-fade .tabset-pills}

## Sample Size

### Overall:

```{r n}
long_data %>% 
  select(sub_id) %>% 
  unique() %>% 
  nrow()
```

### N per Voting Opinion

```{r n by group and voting opin}
long_data %>% 
  select(sub_id, cand_pref) %>% 
  unique() %>% 
  group_by(cand_pref) %>% 
  count()
```

I'm wondering with so few Trump supporters if we should remove them from the analysis... There isn't enough for a comparison condition

## Gender

```{r gender}
long_data %>% 
  na.omit() %>% 
  select(sub_id, gender) %>% 
  unique() %>% 
  group_by(gender) %>% 
  count()
```

## Race/Ethnicity

```{r race}
ethnicity_counts <- long_data %>% 
  select(sub_id, ethnicity) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(ethnicity) %>% 
  count()

ethnicity_counts %>% 
  mutate(n_total = sum(ethnicity_counts$n),
    percent = n/n_total*100) %>% 
  select(-n_total)
```

## Age

```{r age}
long_data %>% 
  select(sub_id, age) %>% 
  na.omit() %>% 
  summarize(mean = mean(age),
            sd = sd(age))
```

## COVID Questions

### Personal experience with COVID

```{r}
long_data %>% 
  select(sub_id, covid1) %>% 
  unique() %>% 
  group_by(covid1) %>% 
  count()
```

### How many people they see

```{r}
long_data %>% 
  select(sub_id, covid2) %>% 
  unique() %>% 
  mutate(covid2 = recode(covid2,
                         `1` = "0 to 2 people",
                         `2` = "3 to 6 people",
                         `3` = "7 to 10 people",
                         `4` = "11 to 15 people",
                         `5` = "16 to 20 people",
                         `6` = "21 or more people")) %>% 
  group_by(covid2) %>% 
  count()
```

### Most important issue related to COVID

```{r}
long_data %>% 
  select(sub_id, covid3) %>% 
  unique() %>% 
  group_by(covid3) %>% 
  count()
```

# Model Comparisons {.tabset .tabset-fade .tabset-pills}

```{r}
# Listwise removal of missing data per item
model_data <- long_data %>% 
  select(sub_id, bfi_number, cand_pref, ingroup_ident, threat, 
         self, target_number_collapsed, target_bfi_value, 
         condition_order, covid1, covid2, covid3, target_group,
         ingroup_ident_c, self_c, threat_c, gender) %>% 
  na.omit(long_data)

```

## Contrasts

### Target number

```{r contrasts 1}
## Dummy coding with first target as reference as wanted
contrasts(model_data$target_number_collapsed) 
```

### Target group

```{r contrasts 2}
## Levels for target group were opposite, so switched them and applied effects coding
## for between-subjects differences of target (which is based on political preference
## - it is the opposite of the target's preference)
levels(model_data$target_group)
model_data$target_group <- relevel(model_data$target_group, "Trump Supporter Target")
contrasts(model_data$target_group) <- contr.sum(2)
```

## Base Model

```{r}
# For reference about nesting: https://www.muscardinus.be/2017/07/lme4-random-effects/
model_base <- lmer(target_bfi_value ~ self_c*target_number_collapsed + (self_c|sub_id), data = model_data)

tab_model(model_base,
          digits = 3)

# Model adding RE for target_number_collapsed at this level did not converge
# mod_vartest_targ <- lmer(target_bfi_value ~ self_c*target_number_collapsed + (self_c + target_number_collapsed|sub_id), data = model_data)
```

## Confirmatory Moderators

### In-group identification

```{r}
mod_vartest_ident <- lmer(target_bfi_value ~ self_c*target_number_collapsed*ingroup_ident_c + (self_c |sub_id), data = model_data)

anova(model_base, mod_vartest_ident)

tab_model(mod_vartest_ident,
          digits = 3)
```

There is a significant difference adding ingroup_ident into the model when doing model comparisons. Checking next model with threat

### Threat

```{r}
mod_vartest_threat <- lmer(target_bfi_value ~ self_c*target_number_collapsed*threat_c + (self_c |sub_id), data = model_data)


anova(model_base, mod_vartest_threat)

anova(mod_vartest_ident, mod_vartest_threat)

tab_model(mod_vartest_threat,
          digits = 3)
```

There is a significant difference between the base model and adding threat, but not between adding threat and adding in-group identification.

Both models show the same pattern of results. There is a main effect of the intervention and a main effect of the moderator, but no interaction of the moderator on the intervention.

## Level 1 Residuals

```{r}
# nlme code did not work, so extracted residuals from lmer and visually inspected

# lm.form <- formula(target_bfi_value ~ 1 + self_c + target_number_collapsed + self_c:target_number_collapsed)
# 
# control1 <- lmeControl(maxIter = 10000, msMaxIter = 10000, niterEM = 10000,
#                        msMaxEval = 10000, opt = c("nlminb"), optimMethod = "BFGS", returnObject=TRUE)
# 
# model_base_nlme1 <- lme(lm.form,
#                         random = ~1 + self_c | sub_id,
#                         data = model_data,
#                         na.action = na.exclude,
#                         varIdent(form = ~1 | sub_id),
#                         control = lmeControl(opt = "optim", tolerance = 1e-3))
# 
# # lmeControl(opt = "optim") # alternative code for control above; doesn't have convergence issue but has allocation issue
# model_base_nlme2 <- lme(lm.form,
#                         random = ~1 + self_c | sub_id,
#                         data = model_data,
#                         na.action = na.exclude)

model_data$predict <- predict(model_base)

model_data$resid <- model_data$target_bfi_value - model_data$predict

model_data$zresid <- (model_data$resid - mean(model_data$resid))/sd(model_data$resid)
```

### Normality

```{r}
hist(model_data$zresid)
```

### Heteroscedasticity: Responses for Self

```{r}
resid_mod1 <- lm(model_data$zresid ~ model_data$self_c)

par(mfrow=c(2,2))
plot(resid_mod1)
par(mfrow=c(1,1))
```

# Confirmatory Visualizations {.tabset .tabset-fade .tabset-pills}

## Target number main effect 

```{r}
ggplot(model_data, aes(self_c, target_bfi_value, group = target_number_collapsed)) +
    geom_smooth(method = "lm", 
                size = .7, 
                colour = "black", 
                aes(linetype = target_number_collapsed)) +
    theme_minimal(base_size = 13) +
    theme(legend.key.size = unit(1, "cm")) +
    labs(title = "Projection by intervention",
         subtitle = "Responses to target 1 were before the intervention. \nResponses to target 2 were after the intervention.",
       x = "BFI responses for self",
       y = "BFI responses for target")
```

## Identification main effect

```{r}
# describe(model_data$ingroup_ident_c)

effects_data_ident <- effect("self_c:ingroup_ident_c",
                         xlevels = list(ingroup_ident_c = c(-0.95, 0, 0.95)),
                         mod = mod_vartest_ident)

effects_data_ident <- as.data.frame(effects_data_ident)
effects_data_ident$ingroup_ident_c <- as.factor(effects_data_ident$ingroup_ident_c)

  
ggplot(effects_data_ident, aes(self_c, fit, group = ingroup_ident_c)) +
    geom_smooth(method = "lm", 
                size = .7, 
                colour = "black", 
                aes(linetype = ingroup_ident_c)) +
    theme_minimal(base_size = 13) +
    theme(legend.key.size = unit(1, "cm")) +
    scale_linetype_manual("Identification",
                        breaks = c(-0.95, 0, 0.95), 
                       labels = c("Low",
                                  "Average",
                                  "High"),
                       values = c("solid",
                                  "dashed",
                                  "dotted")) +
    labs(title = "Projection by in-group identification",
       x = "BFI responses for self",
       y = "BFI responses for target")
```

## Threat main effect

```{r}
describe(model_data$threat_c)

effects_data_threat <- effect("self_c:threat_c",
                         xlevels = list(threat_c = c(-1.3, 0, 1.3)),
                         mod = mod_vartest_threat)

effects_data_threat <- as.data.frame(effects_data_threat)
effects_data_threat$threat_c <- as.factor(effects_data_threat$threat_c)
  
ggplot(effects_data_threat, aes(self_c, fit, group = threat_c)) +
    geom_smooth(method = "lm", 
                size = .7, 
                se = FALSE,
                colour = "black", 
                aes(linetype = threat_c)) +
    theme_minimal(base_size = 13) +
    theme(legend.key.size = unit(1, "cm")) +
  scale_linetype_manual("Threat",
                        breaks = c(-1.3, 0, 1.3), 
                       labels = c("Low",
                                  "Average",
                                  "High"),
                       values = c("solid",
                                  "dashed",
                                  "dotted")) +
    labs(title = "Projection by perceived threat",
       x = "BFI responses for self",
       y = "BFI responses for target")
```

# Exploratory models {.tabset .tabset-fade .tabset-pills}

## Interaction of threat & identification

```{r}
mod_vartest_int <- lmer(target_bfi_value ~ self_c*target_number_collapsed*threat_c*ingroup_ident_c + (self_c |sub_id), data = model_data)

anova(mod_vartest_threat, mod_vartest_int)

anova(mod_vartest_ident, mod_vartest_int)

tab_model(mod_vartest_int,
          digits = 3)
```

Interestingly, adding the interaction of threat and ingroup identification did signficantly differ from the threat covariate model, but did improve upon the model only including identification.

However, there are no higher-order interactions. Instead, we see the main effect of target number and threat remain, while the main effect of in-group identification is no longer significant. It appears threat is the stronger covariate.

## Order

```{r}
mod_vartest_order <- lmer(target_bfi_value ~ self_c*target_number_collapsed*condition_order + (self_c |sub_id), data = model_data)

anova(model_base, mod_vartest_order)

tab_model(mod_vartest_order,
          digits = 3)
```

UH-OH - The target order mattered.... I guess there are differences between men and women?

### Exploring if order effect  is due to participant gender 

```{r}
# Model was rank deficient with other categories
gender_filtered <- model_data %>% 
  filter(gender == "Female" | gender == "Male")

mod_vartest_order2 <- lmer(target_bfi_value ~ self_c*target_number_collapsed*condition_order*gender + (self_c |sub_id), data = gender_filtered)

tab_model(mod_vartest_order2,
          digits = 3)
```

First model is rank deficient, probably because of the categories that were underpowered (7, 1, 1). Gender does not moderate this effect.

## Covid 1

```{r}
mod_vartest_covid1  <- lmer(target_bfi_value ~ self_c*target_number_collapsed*covid1 + (self_c |sub_id), data = model_data)

anova(model_base, mod_vartest_covid1)
```

Adding first Covid filler question (whether or not they had it/knew someone who did OR did not) did not moderate anything, so did not look at results. A surprising number of people fell into the first category.

## Covid 2

```{r}
mod_vartest_covid2  <- lmer(target_bfi_value ~ self_c*target_number_collapsed*covid2 + (self_c |sub_id), data = model_data)

anova(model_base, mod_vartest_covid2)
```

Also not significantly different from the base model.

## Covid 3

```{r}
mod_vartest_covid3  <- lmer(target_bfi_value ~ self_c*target_number_collapsed*covid3 + (self_c |sub_id), data = model_data)

anova(model_base, mod_vartest_covid3)

tab_model(mod_vartest_covid3,
          digits = 3)
```

Main effect of covid 3 filler dummy coded for health, no interactions.

## Voting preference

```{r}
mod_vartest_cand <- lmer(target_bfi_value ~ self_c*target_number_collapsed*cand_pref + (self_c |sub_id), data = model_data)

anova(model_base, mod_vartest_cand)

tab_model(mod_vartest_cand,
          digits = 3)
```

This model is significantly different and all the effects are significant... HOWEVER, the groups are highly different in numbers and this makes me very uncomfortable with these results. We should collect equal numbers to analyze this question.

**Not going to look at visualizations because I do not think these are reliable.

# Exploratory visualizations {.tabset .tabset-fade .tabset-pills}

## Threat accounting for identification 


```{r}
effects_data_threat_int <- effect("self_c:threat_c",
                         xlevels = list(threat_c = c(-1.3, 0, 1.3)),
                         mod = mod_vartest_int)

effects_data_threat_int <- as.data.frame(effects_data_threat_int)
effects_data_threat_int$threat_c <- as.factor(effects_data_threat_int$threat_c)
  
ggplot(effects_data_threat_int, aes(self_c, fit, group = threat_c)) +
    geom_smooth(method = "lm", 
                size = .7, 
                se = FALSE,
                colour = "black", 
                aes(linetype = threat_c)) +
    theme_minimal(base_size = 13) +
    theme(legend.key.size = unit(1, "cm")) +
  scale_linetype_manual("Threat",
                        breaks = c(-1.3, 0, 1.3), 
                       labels = c("Low",
                                  "Average",
                                  "High"),
                       values = c("solid",
                                  "dashed",
                                  "dotted")) +
    labs(title = "Projection by perceived threat",
       x = "BFI responses for self",
       y = "BFI responses for target")
```

Main effect of threat after accounting for in-group identification seems unaffected.

## Interaction of target number and order

```{r}
order_label <- c("o1" = "Order 1 \n(Female target first)", 
                 "o2" = "Order 2 \n(Male target first)")
  
ggplot(model_data, aes(self_c, 
                       target_bfi_value, 
                       group = target_number_collapsed)) +
    geom_smooth(method = "lm", 
                size = .7, 
                colour = "black", 
                aes(linetype = target_number_collapsed)) +
  facet_wrap(~condition_order,
             labeller = labeller(condition_order = order_label)) +
  theme_minimal(base_size = 13) +
  theme(legend.key.size = unit(1, "cm")) +
  scale_linetype_manual("Target",,
                       labels = c("Target 1",
                                  "Target 2"),
                       values = c("solid",
                                  "dashed")) +
    labs(title = "Projection by intervention and target order",
         subtitle = "Responses to target 1 were before the intervention. \nResponses to target 2 were after the intervention.",
       x = "BFI responses for self",
       y = "BFI responses for target")
```


## Main effect of Covid 3

```{r}
ggplot(model_data, aes(self_c, 
                       target_bfi_value, 
                       group = covid3)) +
    geom_smooth(method = "lm", 
                size = .7, 
                colour = "black", 
                aes(linetype = covid3)) +
  theme_minimal(base_size = 13) +
  theme(legend.key.size = unit(1, "cm")) +
  scale_linetype_manual("Concern during Covid",
                       labels = c("Both Economic and Health",
                                  "Economic",
                                  "Health",
                                  "Neither"),
                       values = c("solid",
                                  "dashed",
                                  "dotted",
                                  "longdash")) +
    labs(title = "Projection by primary concern during Covid",
       x = "BFI responses for self",
       y = "BFI responses for target")
```

People whose main concern during Covid was health counter-projected across target variables, while all other participants projected positively to some degree.
